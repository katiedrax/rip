---
title: "Brief - RIP game pilot study"
author: "Kirsty Merrett, Christopher Warren, Katie Drax, & Marcus Munafò"
date: "04/03/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r notes}
###########################################
# 4 March meeting with Kirsty & Christopher ####
######

#Changes
#* No changes to content
#* Pandemic affected ability to trial it & test it, currently working on online version on Roll20
#* Mini-conferences & webinars to speak about game - last on in Nov 2020 & pulled stats on how far & wide game downloaded but no feedback form #submissions. 150 different locations in Nov 2020. Told Wellcome Trust used it in an ECR keynote (when they get them all back 1/2 times a year) = #know it's out there but don't know how it works IRL
#* 1 day of work to get online
#* Feedback form & statistics from online? - Roll20 had free account integrate with Google analytics 
#
#Idea
#* Educational tool that would be steered by library services
#* 2uses
#	* Ice breaker at workshops (select subset of cards to test where people were at) then do round up using same/similar questions to see if #there's a change in knowledge
#	* Ice breaker at events to get people engaged
#	* lunch time game sessions aimed at PGRs
#
#Explained trial idea - any issues?
#* Engaging in a game without background knowledge will be different to engageing in it with an educator BUT more interesting that people who #don't know what it is applying it so probably need a glossary/concept bank if not being run/taught by someone who can explain in purpose
#* discussed glossary but time
#* different audiences may be encountering terms
#* translation maybe difficult as need to find equivalent national idioms for some things - reimburse people to help with this if passes trial?
#
#Learning how other people understand
#Answers? Ones in answer matrix CSV file says the answer cards we created for the questions, doesn't mean only option just how created
#Needed multiple cards of same answer (e.g. "a DOI", "the DOI") to ensure someone would have a playable answer if they wanted to play the "right" #answer
#Send locations & recent stats? Yes we can
#Defend answer? Don't have to defend answer in Cards vs H, but should stop you from playing something random & something that actually happens in #reality. Don't need to defend comic answer, just academic ones that are about IRL e.g. cynical or naiive answers
#Practice game would be good
#Data measurement - spectrum of precision, would it be possible to measure? Not right now, what is the unit you are measuring? If you're measuring #what's in it, no, but if your measuring the existing of data probably ye
#
#Data preparation rules http://www.bristol.ac.uk/staff/researchers/data/publishing-research-data/data-preparation-rules/ & FAIR principles
#* record is universal = (controlled, restricted, open), metadata, https://data.bris.ac.uk/data/dataset/1nufzjw3m9ho72cwisj1pwc75h, 
#* open vs proprietory
#* data present
#* downloadable
#* openable
#* metadata

#################################
## Marcus original points on study ####
###################################

#* evidence can randomise & affects knowledge
#* 3 arms - C vs humanity, UKRN primer on data #sharing/
#* with no active ingrediates
#gamified vs non-gamified educational intervention vs true control
#* tool for assessing quality of data deposits, #see if exists & include Kirsty Merrit
#* ReproducibiliTea - recruitment sample
#* cluster randomised trial = randomising RTea's, #not indivduals within it ~20
#* Kirsty about online delivery
#* RepliCATs reimbursement online
```
# Background

Members of the University of Bristol’s Research Data Service created the Researchers, Impact, and Publications (RIP) game (Merrett & Warren, 2020). 
Adapted “Cards Against Humanity”, the RIP game aims help people learn about research data management and its relationship to funding and publishing research. 
The Research Data Service are in the process of creating an online version of the card game using Roll20.com. 
Data in November 2020 showed the RIP game data had been downloaded in over 150 different locations.

# Study rationale

Educational interventions can raise researchers’ awareness and understanding of data sharing and gamifying these interventions could encourage engagement with them and increase uptake within the community. 
The RIP game could have numerous and low-cost applications if effective. 
The current cards are in English and focus on data management but could be translated and adapted for different topics. 
A randomised controlled trial (RCT) could establish the efficacy of the cards in increasing data sharing since participants can be followed over time. 
We plan to conduct a pilot to inform a future RCT and confirm its feasibility.

# Research questions

The first research question will be: "does the RIP game improve understanding of data management?".
To answer this research question we will randomise groups to the intervention or a control group and they will complete a questionnaire before and after the intervention.
The questionnaire will contain a multiple choice quiz on data management.
The primary outcome will be the number of correct answers people provide to the data management quiz.

The second research question will be: "what is the feasibility of conducting a RCT of the RIP game's efficacy in increasing data sharing?".
To answer this research question we will conduct a pilot which will provide evidence for the feasibility and costs of a full RCT.
We will also develop a measure to assess the quality of data sharing.

# Pilot

The pilot will compare three arms: the RIP game, UK Reproducibility Network primer on data sharing, and a control group who will play an online quiz together.
We will recruit existing ReproducibiliTea journal clubs and randomise them to one of the arms.
Cluster randomisation is preferable here to individual randomisation.
Participants will receive financial reimbursement for their time.

We will need to adapt the existing RIP game into an online version before beginning the pilot. 
Creators also designed the game to be delivered with an educator so designing a glossary or concept bank document will help adapt the game for play without an educator.

# Data sharing measure

To measure data sharing across multiple disciplines, institutions, languages, and countries we will need to measure universal indicators of data sharing. 
There are numerous checklists and guidelines for data management plans and data sharing, but most are designed for specific types of data and few aims to be universal. 
One example of famous universal guidelines are the FAIR principles who claim, “All scholarly digital research objects—from data to analytical pipelines—benefit from application of these principles”. 
Regarding universality, Kirsty Merrett and Christopher Warren suggested the most universal aspect of data sharing will be the data deposit record. 
The record includes:

* Data
* File formats
* License
* Creator(s) names
* Identifier
* Metadata

Our data sharing measure could adapt the FAIR principles, Kirsty and Christopher’s suggestions, or a combination.
Essentially universal standards about the “content” of shared data will be very difficult to develop. 
Universal standards about the presence of shared data will be easier.

# Inital questions

* Ceiling effects of ReproducibiliTea?
  * Could put out a call for anyone interested in taking part in online research
*	We could try to randomise individuals - but this may mean strangers are playing together which could yield quite different effects
*	Cluster randomisation is at risk of bias from differences in baseline characteristics. How can we control for this? Deception?
  * Differences in baseline characteristics don't matter
  * New educational materials, randomly allocated to 1 of 3 conditions

*	Whether or not we let the groups organise themselves will influence how easy it is to administer & receive the questionnaires. How can we balance this?
  –	Link with reimbursement (anonymous data collection yay!
  –	Don’t need before and after b/c baseline differences don’t matter

*	How can we handle attrition of clusters & individuals from cluster? This was an issue in MAPS.
  –	Not an issue because it’s a one off
*	I do not think concealing allocation from the clusters will be possible. How can we minimise this risk of bias?
  –	Educational materials, control condition maybe an issue
*	Will we need to validate the data sharing measure e.g. inter-rater reliability?
  - Yes good idea
*	There is lots of behavioural theory we could draw on here, e.g. theory of planned behaviour, what do you think?
  - Research question is: does gamification improves retention of knowledge? Static educational materials vs gamified card version

# References

Merrett, K., & Warren, C. (2020). Researchers, Impact & Publications (R.I.P.) Game data (01-2020). https://doi.org/10.5523/bris.1nufzjw3m9ho72cwisj1pwc75h
Wilkinson, M. D., Dumontier, M., Aalbersberg, Ij. J., Appleton, G., Axton, M., Baak, A., Blomberg, N., Boiten, J.-W., da Silva Santos, L. B., Bourne, P. E., Bouwman, J., Brookes, A. J., Clark, T., Crosas, M., Dillo, I., Dumon, O., Edmunds, S., Evelo, C. T., Finkers, R., … Mons, B. (2016). The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data, 3(1), 160018. https://doi.org/10.1038/sdata.2016.18 